.\" Version: 1.001 
.\"
.TH ocf_suse_SAPFilesystem 7 "05 Aug 2023" "" "OCF resource agents"
.\"
.SH NAME
SAPHanaFilesystem \- Monitors mounted SAP HANA filesystems.
.PP
.\"
.SH SYNOPSIS
\fBSAPHanaFilesystem\fP [start | stop | status | monitor | meta\-data | validate\-all | methods | usage ]
.PP
.\"
.SH DESCRIPTION
SAPHanaFilesystem is a resource agent (RA) that monitors mounted SAP HANA filesystems
by checking read/write access. This RA does neither mount nor umount any filesystem.
In case the filesystem monitor fails, the RA decides how to proceed based on
HANA system replication status.
The monitor and action timeouts can be significantly shorter than SAPHanaController
resource timeouts. This results in faster takeover actions.
.PP
* Behaviour on HANA primary sites
.PP
srHook=SOK: In case of monitor failure the Linux cluster tries to stop and restart
the SAPHanaFilesystem resource (not the real filesystem). If that stop fails and
the HANA system replication is in sync the node gets fenced. In consequence an
HANA sr_takeover will be triggered.
.br
srHook=SFAIL: In case of monitor failure the Linux cluster tries to stop and restart
the SAPHanaFilesystem resource (not the real filesystem). If the HANA system
replication is not in sync this will be repeated until it gains success or
migration-threshold is reached.
.PP
* Behaviour on HANA secondary sites
.PP
In case of monitor failure the Linux cluster tries to stop and restart the
SAPHanaFilesystem resource (not the real filesystem). This will be repeated until
it gains success or migration-threshold is reached.
.\" TODO migration-threshold?
.PP
* Rational
.PP
For HANA scale-out systems, the directory /hana/shared/$SID/ is provided as NFS
share to all nodes of a site. The directory contains binaries, tools and other
components needed for running and monitoring the HANA database. 
The NFS share for /hana/shared/$SID/ is mounted by the OS as usual.
In case of NFS failure, HANA might stop working but the Linux cluster might not
take action in reasonable time.
Due to obligatory NFS for the directory /hana/shared/$SID/, scale-out systems
are affected more often than scale-up systems.
Even if SAPHanaFilesystem improves Linux cluster reaction on failed NFS shares,
reliable filesystems are cornerstones for SAP HANA database availability.  
.PP
The resource agent uses the HANA interface hdbnsutil.
This interface allows to check the "topology" of the system
replication as well as the current configuration (primary/secondary) of a
SAP HANA database. A second task of the interface is the posibility to run
a system replication takeover (sr_takeover) or to register a former primary
to a newer one (sr_register). In scale-out setups, hdbnsutil sometimes
might take some time. SAPHanaFilesystem uses only task one.
.\" TODO how is sr checked?
.PP
Please see also the REQUIREMENTS section below.
.PP
.\"
.SH SUPPORTED PARAMETERS
This resource agent supports the following parameters:
.PP
\fBSID\fR
.RS 4
SAP System Identifier. Has to be same on both instances.
Example "SID=SLE".
.RE
.PP
.\" TODO InstanceNumber?
.\" \fBInstanceNumber\fR
.\" .RS 4
.\" Number of the SAP HANA database.
.\" For system replication also Instance Number+1 is blocked.
.\" Example "InstanceNumber=00".
.\" .RE
.\" .PP
\fBDIRECTORY\fR
.RS 4
Path to directory to be monitored.
TODO NFS see TID
Optional. Default value: "/hana/shared/$SID/".
.RE
.PP
\fBHANA_CALL_TIMEOUT\fR
.RS 4
Define timeout how long a call to HANA to receive information can take. This
could be e.g. hdbnsutil.
There are some specific calls to HANA which have their own timeout values.
For example the sr_takeover command does not timeout (inf).
If the timeout is reached, the return code will be 124. If you increase the
timeouts for HANA calls you should also adjust the operation timeouts of your
Linux cluster resources.
.br
Optional. Default value: "120". TODO
.RE
.PP
.\"
.SH SUPPORTED PROPERTIES
\fBhana_${sid}_glob_filter\fR
.RS 4
Global cluster property \fBhana_${sid}_glob_filter\fR . This property defines which messages are logged by the RA. It should only be set if requested by support engineers. The default is sufficient for normal operation.
.br
Message Types: [ act | dbg | dec | flow | top ]
.\" TODO dbg2?
.\" TODO message levels: (dbg)|info|warn|err|error
.br
ACT: Action. Start, stop, sr_takeover and others. See also section SUPPORTED ACTIONS.
.br
DBG: Debugging info. Usually not needed at customer site. See SUSE TID 7022678 for maximum RA tracing.
.br
DEC: Decision taken by the RA.
.br
FLOW: Function calls and the respective return codes.
.RE
.PP
.\"
.SH SUPPORTED ACTIONS
.br
This resource agent supports the following actions (operations):
.\" TODO aligne with timeouts in saphana-filesystem-lib
.PP
\fBstart\fR
.RS 4
Sets the status of the clone to "started". No filesystem action is done.
Suggested minimum timeout: 60\&.
.RE
.PP
\fBstop\fR
.RS 4
Sets the status of the clone to "stopped". No filesystem action is done.
Suggested minimum timeout: 60\&.
.RE
.PP
\fBstatus\fR
.RS 4
Reports whether the SAPHanaFilesystem resource (not the filesystem) is running.
Suggested minimum timeout: 60\&.
.RE
.PP
\fBmonitor\fR
.RS 4
Checks access to the path specified in parameter DIRECTORY.
The check is done by creating a sub-directory and writing a file.
.\" TODO default timeout
Suggested minimum timeout: 120\&.
Suggested interval: 120\&.
.RE
.PP
\fBvalidate\-all\fR
.RS 4
Reports whether the parameters are valid.
Suggested minimum timeout: 5\&.
.RE
.PP
\fBmeta\-data\fR
.RS 4
Retrieves resource agent metadata (internal use only).
Suggested minimum timeout: 5\&.
.RE
.PP
\fBmethods\fR
.RS 4
Suggested minimum timeout: 5\&.
.RE
.PP
.\"
.SH RETURN CODES
The return codes are defined by the OCF cluster framework.
Please refer to the OCF definition on the website mentioned below.
.br
In addition return code 124 is used if HANA_CALL_TIMEOUT has been exceeded.
.PP
.\"
.SH EXAMPLES
* Example configuration for a SAPHanaFilesystem resource for HANA scale-up.
.br
Might be useful if NFS is used for the /hana/shared/ filesystem instead of classical
block devices. One NFS share is used per node. The NFS is not shared across sites.
On each cluster node the NFS share is mounted statically.
.PP
.RS 4
primitive rsc_SAPHanaFil_SLE_HDB00 ocf:suse:SAPHanaFilesystem \\
.br
op start interval="0" timeout="60" \\
.br
op stop interval="0" timeout="60" \\
.br
op monitor interval="120" timeout="120" \\
.br
params SID="SLE" InstanceNumber="00"
.PP
clone cln_SAPHanaFil_SLE_HDB00 rsc_SAPHanaFil_SLE_HDB00 \\
.br
notify="true" interleave="true" clone-node-max="1"
.RE
.PP
* Example configuration for a SAPHanaFilesystem resource for HANA scale-out.
.br
The HANA consists of two sites with several nodes each. An additional cluster node
is used as majority maker for split brain situations. One /hana/shared/ filesystem
is used per site. This filesystem is provided by an NFS server and shared among
all cluster nodes of that site. The NFS is not shared across sites. On each cluster
node the NFS share is mounted statically.
.PP
.RS 4
primitive rsc_SAPHanaFil_SLE_HDB00 ocf:suse:SAPHanaFilesystem \\
.br
op start interval="0" timeout="60" \\
.br
op stop interval="0" timeout="60" \\
.br
op monitor interval="120" timeout="180" \\
.br
params SID="SLE" InstanceNumber="00"
.PP
clone cln_SAPHanaFil_SLE_HDB00 rsc_SAPHanaFil_SLE_HDB00 \\
.br
notify="true" interleave="true" clone-node-max="1"
.PP
location SAPHanaFil_not_on_majority_maker cln_SAPHanaFIL_SLE_HDB00 -inf: vm-majority
.RE
.PP
* Example on showing the current SAPHanaFilesystem rescource configuration on scale-out.
.br
The primitive is "rsc_SAPHanaFil_SLE_HDB00" and clone is "cln_SAPHanaFil_SLE_HDB00".
The contsraints´ names are starting with "SAPHanaFil".
.RE
.PP
.RS 4
# crm configure show | grep SAPHanaFil_
.br
# crm configure show rsc_SAPHanaFil_SLE_HDB00
.br
# crm configure show cln_SAPHanaFil_SLE_HDB00
.br
# crm configure show SAPHanaFil_not_on_majority_maker
.RE
.PP
* Search for log entries of the resource agent. Show errors only.
.PP
.RS 4
# grep "SAPHanaFilesystem.*RA.*rc=[1-7,9]" /var/log/messages
.RE
.PP
* Search for log entries of the resource agent.  Show date, time, return code, runtime.
.PP
.RS 4
# grep "SAPHanaFilesystem.*end.action.monitor_clone.*rc=" /var/log/messages | awk '{print $1,$11,$13}' | colrm 20 32 | tr -d "=()rsc" | tr "T" " "
.RE
.PP
* Search for log entries of the resource agent. Show poison pill only.
.br
.PP
.RS 4
# grep "SAPHanaFilesystem.*RA.*poison.pill.detected" /var/log/messages
.RE
.PP
* Search for fence action caused by resource stop failure.
.br
.PP
.RS 4
# grep "Stop.of.failed.*is.fenced" /var/log/messages
.RE
.PP
* Show failcount for resource agent.
.br
SID is SLE, instance number is 00.
See also cluster properties migration-threshold and failure-timeout.
.PP
.RS 4
# cibadmin -Ql | grep rsc_SAPHanaFil_SLE_HDB00.*fail-count
.RE
.PP
* Example for static NFS mount.
.br
This is an example line in /etc/fstab. NFS server is nfs1, SID is SLE. The NFS share will
be mounted at OS boot time. The shown export path and mount options need to be adjusted
for the NFS server in use. See manual pages nfs(5) and fstab(5) for details.
.PP
.RS 4
nfs1:/export/SLE/shared/ /hana/shared/SLE/ auto defaults,rw,hard,proto=tcp,intr,noatime,vers=4,lock 0 0
.RE
.PP
.\"
.SH FILES
.TP
/usr/lib/ocf/resource.d/suse/SAPHanaController
the controller resource agent
.TP
/usr/lib/ocf/resource.d/suse/SAPHanaTopology
the topology resource agent
.TP
/usr/lib/ocf/resource.d/suse/SAPHanaFilesystem
the filesystem monitoring resource agent
.TP
/usr/lib/SAPHanaSR-angi/
the directory with function libraries
.TP
.\" TODO path and filename? E.g. "/hana/shared/$SID/check/"
$DIRECTORY/tmp/test
the resource´s path used for monitoring, default DIRECTORY=/hana/shared/$SID/
.TP
$HA_RSCTMP/ TODO
the resource´s status file, do not touch this
.TP
.\" TODO poison pill file should be unique, like full resource name
/dev/shm/poison_pill_$SID 
the resource´s poison pill file, do not touch this
.TP
/etc/fstab
the static information about the filesystems
.\"
.PP
.SH REQUIREMENTS
For the current version of the SAPHanaFilesystem resource agent that comes with
the software package SAPHanaSR-angi, the support is limited
to the scenarios and parameters described in the respective manual page
SAPHanaSR-angi(7) and its references.
.PP
.\"
.SH SEE ALSO
\fBocf_suse_SAPHanaController\fP(7) , \fBocf_suse_SAPHanaTopology\fP(7) ,
\fBsusHanaSR.py\fP(7) , \fBSAPHanaSR-showAttr\fP(8) ,
\fBSAPHanaSR-angi\fP(7) , \fBSAPHanaSR\fP(7) , \fBSAPHanaSR-ScaleOut\fP(7) ,
\fBfstab\fP(5) , \fBmount\fP(8) , \fBnfs\fP(5) ,
.br
https://documentation.suse.com/sbp/sap/ ,
.br
https://www.suse.com/support/kb/doc/?id=000019904
.PP
.\"
.SH AUTHORS
F.Herschel, L.Pinne.
.PP
.\"
.SH COPYRIGHT
.br
(c) 2023 SUSE LLC
.br
SAPHanaFilesystem comes with ABSOLUTELY NO WARRANTY.
.br
For details see the GNU General Public License at
http://www.gnu.org/licenses/gpl.html
.\"
